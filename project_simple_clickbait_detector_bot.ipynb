{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Library Imports"
      ],
      "metadata": {
        "id": "_rKadGBfW4_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28.0 comet_llm pandas numpy --quiet"
      ],
      "metadata": {
        "id": "dXZPEqWpXBpA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVCULF5yWyDv",
        "outputId": "d1cb2af9-d36a-4330-86f3-012490548009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n"
          ]
        }
      ],
      "source": [
        "import comet_llm\n",
        "import openai\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import userdata\n",
        "\n",
        "# API configuration\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')\n",
        "COMET_API_KEY = userdata.get('COMET_API_KEY')\n",
        "COMET_WORKSPACE = userdata.get('COMET_WORKSPACE')\n",
        "\n",
        "# Initialize Comet for logging\n",
        "comet_llm.init(project=\"my_clickbait_detection_project\", api_key=COMET_API_KEY)\n",
        "\n",
        "# Load Training Data\n",
        "with open('/content/data/headlines_dataset.txt', 'r') as file:\n",
        "    training_data = json.load(file)\n",
        "training_df = pd.DataFrame(training_data)\n",
        "\n",
        "# Load Evaluation Data\n",
        "with open('/content/data/evaluation_data.txt', 'r') as file:\n",
        "    evaluation_data = json.load(file)\n",
        "evaluation_df = pd.DataFrame(evaluation_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation and Templates."
      ],
      "metadata": {
        "id": "1_bGp9OxXbAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing data for processing\n",
        "training_headlines = training_df['headline'].tolist()\n",
        "training_labels = training_df['category'].tolist()\n",
        "evaluation_headlines = evaluation_df['headline'].tolist()\n",
        "evaluation_labels = evaluation_df['tag'].tolist()\n",
        "\n",
        "\n",
        "# Zero-shot prompt template\n",
        "zero_shot_template = \"\"\"\n",
        "A headline is considered 'clickbait' if it:\n",
        "1. Uses sensationalist or exaggerated language.\n",
        "2. Teases the reader about a topic without providing substantial information.\n",
        "3. Uses misleading statements or half-truths.\n",
        "4. Provokes curiosity or emotional reaction to entice clicks.\n",
        "\n",
        "Read the following headline and classify it as 'Clickbait' or 'Legit':\n",
        "\n",
        "Headline: {headline}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Few-shot prompt template\n",
        "few_shot_examples = training_df.sample(6).to_dict(orient='records')\n",
        "few_shot_template = \"\"\"\n",
        "A headline is considered 'clickbait' if it:\n",
        "1. Uses sensationalist or exaggerated language.\n",
        "2. Teases the reader about a topic without providing substantial information.\n",
        "3. Uses misleading statements or half-truths.\n",
        "4. Provokes curiosity or emotional reaction to entice clicks.\n",
        "\n",
        "Examples:\n",
        "\"\"\" + \"\\n\".join([f\"Headline: {example['headline']}\\nClassification: {example['category']}\" for example in few_shot_examples]) + \"\"\"\n",
        "\n",
        "Read the following headline and classify it as 'Clickbait' or 'Legit':\n",
        "\n",
        "Headline: {headline}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# CoT prompt template - revised for clearer responses\n",
        "cot_template = \"\"\"\n",
        "Your task is to classify the following headline as either 'Clickbait' or 'Legit'.\n",
        "\n",
        "Headline: {headline}\n",
        "\n",
        "Considerations for 'Clickbait':\n",
        "- Uses sensationalist or exaggerated language.\n",
        "- Teases the reader without providing substantial information.\n",
        "- Contains misleading statements or half-truths.\n",
        "- Provokes curiosity or emotional reaction to entice clicks.\n",
        "\n",
        "Considerations for 'Legit':\n",
        "- Provides clear and straightforward information.\n",
        "- Lacks sensationalism or provocative elements.\n",
        "\n",
        "Classification:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "kt8byVw8XbuN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for LLM Interactions and Headline Processing."
      ],
      "metadata": {
        "id": "SHmZByKLXopN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get a response from the GPT-3.5 Turbo model\n",
        "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature,\n",
        "        max_tokens=max_tokens,\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "def moderate_content(headline):\n",
        "    response = openai.Moderation.create(\n",
        "        input=headline,\n",
        "        model=\"text-moderation-stable\"\n",
        "    )\n",
        "    return response\n",
        "\n",
        "def rewrite_headline(headline):\n",
        "    rewrite_prompt = f\"Rewrite the following headline to be safe and not contain clickbait:\\n\\n{headline}\"\n",
        "    rewritten_headline = get_completion([{\"role\": \"user\", \"content\": rewrite_prompt}])\n",
        "    return rewritten_headline.strip()\n",
        "\n",
        "# Function to process headlines with CoT\n",
        "def process_headlines_with_cot(headlines, cot_template):\n",
        "    cot_responses = []\n",
        "    for headline in headlines:\n",
        "        cot_prompt = cot_template.format(headline=headline)\n",
        "        cot_response = get_completion([{\"role\": \"user\", \"content\": cot_prompt}])\n",
        "        cot_responses.append(cot_response.strip())\n",
        "    return cot_responses\n",
        "\n",
        "# Classify and rewrite headlines based on safety\n",
        "safe_headlines = []\n",
        "unsafe_headlines = []\n",
        "rewritten_unsafe_headlines = {}\n",
        "\n",
        "for headline in training_headlines + evaluation_headlines:\n",
        "    moderation_result = moderate_content(headline)\n",
        "    if any(result[\"flagged\"] for result in moderation_result[\"results\"]):\n",
        "        unsafe_headlines.append(headline)\n",
        "        rewritten_headline = rewrite_headline(headline)\n",
        "        rewritten_unsafe_headlines[headline] = rewritten_headline\n",
        "    else:\n",
        "        safe_headlines.append(headline)\n",
        "\n",
        "# Update the headlines lists with rewritten versions\n",
        "updated_training_headlines = [rewritten_unsafe_headlines.get(h, h) for h in training_headlines]\n",
        "updated_evaluation_headlines = [rewritten_unsafe_headlines.get(h, h) for h in evaluation_headlines]"
      ],
      "metadata": {
        "id": "JWkVagVKXjyv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate predictions for a list of headlines using a specific template\n",
        "def generate_predictions(prompt_template, headlines):\n",
        "    \"\"\"\n",
        "    Generates predictions for a list of headlines based on a specified prompt template.\n",
        "\n",
        "    Args:\n",
        "        prompt_template (str): The prompt template for generating predictions.\n",
        "        headlines (list): List of headlines to generate predictions for.\n",
        "\n",
        "    Returns:\n",
        "        list: List of predictions for each headline.\n",
        "    \"\"\"\n",
        "    predictions = []\n",
        "    for headline in headlines:\n",
        "        prompt = prompt_template.format(headline=headline)\n",
        "        response = get_completion([{\"role\": \"user\", \"content\": prompt}])\n",
        "        predictions.append(response.strip())\n",
        "    return predictions\n",
        "\n",
        "# Generate zero-shot, few-shot, and CoT predictions\n",
        "zero_shot_predictions = generate_predictions(zero_shot_template, updated_evaluation_headlines)\n",
        "few_shot_predictions = generate_predictions(few_shot_template, updated_evaluation_headlines)\n",
        "cot_responses = process_headlines_with_cot(updated_evaluation_headlines, cot_template)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVOM-LRfXss3",
        "outputId": "36375936-65dc-4211-c1e9-e766b69356a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chain logged to https://www.comet.com/blaqadonis/my-clickbait-detection-project\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:comet_llm.summary:Chain logged to https://www.comet.com/blaqadonis/my-clickbait-detection-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluator Prompt\n",
        "evaluator_prompt = \"\"\"\n",
        "You are an evaluator analyzing headlines for clickbait. For each headline, you will be given a prediction stating whether it is 'Clickbait' or 'Legit'. Your task is to assess if this prediction matches the headline's expected label of either Clickbait or Legit.\n",
        "\n",
        "For each headline and its prediction below, please respond with 'Correct' if the prediction matches the expected label, or 'Incorrect' if it does not.\n",
        "\n",
        "Headlines and Predictions:\n",
        "{headline_predictions}\n",
        "\n",
        "Your evaluation:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "y13jwybYXxY_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to format all predictions for the evaluator\n",
        "def format_all_predictions_for_evaluator(headlines, predictions, expected_labels):\n",
        "    \"\"\"\n",
        "    Formats all predictions along with their headlines and expected labels for evaluation.\n",
        "\n",
        "    Args:\n",
        "        headlines (list): List of headlines.\n",
        "        predictions (list): List of predictions corresponding to the headlines.\n",
        "        expected_labels (list): List of expected labels for the headlines.\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted string for all predictions.\n",
        "    \"\"\"\n",
        "    formatted_predictions = \"\\n\".join([f\"Headline: \\\"{headline}\\\", Prediction: {prediction}, Expected: {expected_label}\"\n",
        "                                        for headline, prediction, expected_label in zip(headlines, predictions, expected_labels)])\n",
        "    return formatted_predictions\n",
        "\n",
        "\n",
        "def evaluate_prediction(bot_prediction, expected_tag):\n",
        "    \"\"\"\n",
        "    Evaluates a bot's prediction against the expected tag.\n",
        "\n",
        "    Args:\n",
        "        bot_prediction (str): The bot's prediction for a headline.\n",
        "        expected_tag (str): The expected classification for the headline.\n",
        "\n",
        "    Returns:\n",
        "        str: 'Correct' if the bot's prediction matches the expected tag, otherwise 'Incorrect'.\n",
        "    \"\"\"\n",
        "    # Simplify the bot's prediction to either 'Clickbait' or 'Legit'\n",
        "    classification = \"Clickbait\" if \"Clickbait\" in bot_prediction else \"Legit\"\n",
        "\n",
        "    # Determine if the prediction matches the expected tag\n",
        "    return \"Correct\" if classification == expected_tag else \"Incorrect\"\n",
        "\n",
        "# Function to evaluate each prediction individually\n",
        "def evaluate_individual_predictions(evaluator_prompt, headlines, predictions, expected_labels):\n",
        "    \"\"\"\n",
        "    Evaluates each prediction individually using a given evaluator prompt.\n",
        "\n",
        "    Args:\n",
        "        evaluator_prompt (str): The evaluator prompt template.\n",
        "        headlines (list): List of headlines.\n",
        "        predictions (list): List of predictions for the headlines.\n",
        "        expected_labels (list): List of expected labels for the headlines.\n",
        "\n",
        "    Returns:\n",
        "        list: List of individual evaluation responses for each prediction.\n",
        "    \"\"\"\n",
        "    evaluations = []\n",
        "    for headline, prediction, expected_label in zip(headlines, predictions, expected_labels):\n",
        "        formatted_prediction = f\"Headline: \\\"{headline}\\\", Prediction: {prediction}, Expected: {expected_label}\"\n",
        "        evaluator_response = get_completion([{\"role\": \"user\", \"content\": evaluator_prompt.format(headline_predictions=formatted_prediction)}])\n",
        "        evaluations.append(evaluator_response.strip())\n",
        "    return evaluations\n",
        "\n",
        "# Format all predictions for evaluation (this function is unchanged)\n",
        "formatted_zero_shot_predictions = format_all_predictions_for_evaluator(evaluation_headlines, zero_shot_predictions, evaluation_labels)\n",
        "formatted_few_shot_predictions = format_all_predictions_for_evaluator(evaluation_headlines, few_shot_predictions, evaluation_labels)\n",
        "formatted_cot_predictions = format_all_predictions_for_evaluator(evaluation_headlines, cot_responses, evaluation_labels)\n",
        "\n",
        "# Evaluate each set of predictions individually\n",
        "zero_shot_evaluations = evaluate_individual_predictions(evaluator_prompt, evaluation_headlines, zero_shot_predictions, evaluation_labels)\n",
        "few_shot_evaluations = evaluate_individual_predictions(evaluator_prompt, evaluation_headlines, few_shot_predictions, evaluation_labels)\n",
        "cot_evaluations = evaluate_individual_predictions(evaluator_prompt, evaluation_headlines, cot_responses, evaluation_labels)\n"
      ],
      "metadata": {
        "id": "Rj3Xr1rPX3R0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logging Evaluations to Comet LLM."
      ],
      "metadata": {
        "id": "WYZ1dwTxX_4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enhanced Logging to Comet LLM without prompt template in metadata\n",
        "for i, headline in enumerate(updated_evaluation_headlines):\n",
        "    # Ensure indices are within range\n",
        "    if i >= len(zero_shot_evaluations) or i >= len(few_shot_evaluations) or i >= len(cot_evaluations):\n",
        "        continue\n",
        "\n",
        "    # Determine the expected tag for the headline\n",
        "    original_headline = next((h for h, rh in rewritten_unsafe_headlines.items() if rh == headline), headline)\n",
        "    expected_tag = evaluation_labels[evaluation_headlines.index(original_headline)]\n",
        "\n",
        "    # Fetch the evaluation for each type of prediction\n",
        "    zero_shot_evaluation = zero_shot_evaluations[i]\n",
        "    few_shot_evaluation = few_shot_evaluations[i]\n",
        "    cot_evaluation = cot_evaluations[i]\n",
        "\n",
        "    # Determine if the headline was rewritten for safety\n",
        "    safety_check = \"rewritten\" if headline in rewritten_unsafe_headlines.values() else \"original\"\n",
        "\n",
        "    # Log zero-shot prediction and evaluation\n",
        "    comet_llm.log_prompt(\n",
        "        prompt=zero_shot_template.format(headline=headline),\n",
        "        output=zero_shot_evaluation,\n",
        "        tags=[\"zero-shot\", \"clickbait-detection\"],\n",
        "        metadata={\n",
        "            \"headline\": headline,\n",
        "            \"bot_prediction\": zero_shot_predictions[i],\n",
        "            \"expected_tag\": expected_tag,\n",
        "            \"evaluation\": zero_shot_evaluation,\n",
        "            \"safety_check\": safety_check\n",
        "        },\n",
        "        api_key=COMET_API_KEY\n",
        "    )\n",
        "\n",
        "    # Log few-shot prediction and evaluation\n",
        "    comet_llm.log_prompt(\n",
        "        prompt=few_shot_template.format(headline=headline),\n",
        "        output=few_shot_evaluation,\n",
        "        tags=[\"few-shot\", \"clickbait-detection\"],\n",
        "        metadata={\n",
        "            \"headline\": headline,\n",
        "            \"bot_prediction\": few_shot_predictions[i],\n",
        "            \"expected_tag\": expected_tag,\n",
        "            \"evaluation\": few_shot_evaluation,\n",
        "            \"safety_check\": safety_check\n",
        "        },\n",
        "        api_key=COMET_API_KEY\n",
        "    )\n",
        "\n",
        "    # Log CoT prediction and evaluation\n",
        "    comet_llm.log_prompt(\n",
        "        prompt=cot_template.format(headline=headline),\n",
        "        output=cot_evaluation,\n",
        "        tags=[\"CoT\", \"clickbait-detection\"],\n",
        "        metadata={\n",
        "            \"headline\": headline,\n",
        "            \"bot_prediction\": cot_responses[i],\n",
        "            \"expected_tag\": expected_tag,\n",
        "            \"evaluation\": cot_evaluation,\n",
        "            \"safety_check\": safety_check\n",
        "        },\n",
        "        api_key=COMET_API_KEY\n",
        "    )\n"
      ],
      "metadata": {
        "id": "BxBAwCpAX3P1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ib3QHDhHX3N3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rewrite"
      ],
      "metadata": {
        "id": "NmvkxDmc3EKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to check for unsafe content based on violence and hate\n",
        "def is_headline_unsafe(headline):\n",
        "    moderation_result = moderate_content(headline)\n",
        "    return any(result['categories'].get('hate') or result['categories'].get('violence')\n",
        "               for result in moderation_result['results'])\n",
        "\n",
        "# Function to rewrite headlines and log them\n",
        "def process_and_log_headlines(dataset_name, headlines):\n",
        "    for original_headline in headlines:\n",
        "        if is_headline_unsafe(original_headline):\n",
        "            rewritten_headline = rewrite_headline(original_headline)\n",
        "            # Log original and rewritten headline to Comet\n",
        "            comet_llm.log_prompt(\n",
        "                prompt=\"Original Headline: \" + original_headline,\n",
        "                output=\"Rewritten Headline: \" + rewritten_headline,\n",
        "                tags=[\"headline-rewriting\", \"dataset:\" + dataset_name],\n",
        "                metadata={\n",
        "                    \"original_headline\": original_headline,\n",
        "                    \"rewritten_headline\": rewritten_headline,\n",
        "                    \"dataset\": dataset_name\n",
        "                },\n",
        "                api_key=COMET_API_KEY\n",
        "            )\n",
        "\n",
        "# Process training and evaluation data\n",
        "process_and_log_headlines(\"training\", training_headlines)\n",
        "process_and_log_headlines(\"evaluation\", evaluation_headlines)\n"
      ],
      "metadata": {
        "id": "4eFcNmiQX3L2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dj8SOpbpX3Jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T5UAfqVNX3Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7V4NBkzX3FR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kg68m8sGX3C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JUgVS9AFX3Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EErAECZEX2-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eGbH3nFkX28L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3oG9BA-X26F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v5_jAOpxX231"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yoQHBBWKX21f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZnxHnUchX2ze"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}